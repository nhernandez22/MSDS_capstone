---
title: 'Exploratory Data Analysis: OpenBeta Climbing Data (2022)'
author: "Nina"
date: '2022-05-30'
output:
  html_document:
    df_print: paged
tags:
- R Markdown
- plot
- regression
categories:
- R
- Visualizations
---
## Introduction 
     The population of climbers is exploding and we need more and better access to data to make the sport more accessible. I am using data provided from OpenBeta, a nonprofit built and run by climbers that enables “open access and innovative uses of climbing data” (1).  I built a Shiny app that includes a map of sport and trad climbing routes in Oregon ranked by route quality and a recommendation engine tailored to the user of any skill level.  
     Following the sport of climbing’s Olympic debut in Tokyo 2021 and the success of films like *Free Solo* featuring Alex Honnold (2018) and *The Dawn Wall* featuring Tommy Caldwell (2018), the industry is seeing historic growth and opportunities for new, profitable markets. According to *Forbes*, Google searches that included the term “climbing” reached an all time high in the first week of August 2021; the same time frame that men’s and women’s combined events were held (2). Not only is the sport gaining a bigger audience, but it is also attracting regular people like you and me to take a crack at the crag. Following the pandemic, nearly 100 climbing gyms have opened in North America and profits of El Cap, one of America’s largest operators of climbing facilities, saw a 100% increase in online interactions (2).  
     
     One concern with the sport’s booming popularity is the barrier to entry and as a result, there has been a push to make the sport more accessible. In addition, there are only a few databases with outdoor climbing routes that are in access to the public like The Mountain Project or 8A. Without these platforms, climbers who are looking to hit their local crag or boulder may not be able to find routes or know about the quality of them if they do not already have community or word of mouth. While these websites have provided helpful tools to climbers of all experience and skill levels, they are still heavily lacking data and scrapings of these platforms have resulted in DMCA take downs or lawsuits (3). At the bare minimum, we need better and easier access to climbing data so that data scientists like myself can work to advance the sport for others. As the sport grows so will the influx of data, and with any field that is expanding and rapidly changing, data science can add value to it by making better-informed decisions for multiple stakeholders, generating new insights about its players and audience, and increasing the overall experience for users.  
      OpenBeta is a non-profit built and run by climbers that enables “open access and innovative uses of climbing data” (1). Though they have also faced several challenges with their attempt to use onX’s data from the Mountain Project with copyright infringement and blocked repositories, according to *Outside Learn* (3). At the moment their data is public, and Github recently reversed the DMCA takedown thanks to legal efforts from the owner, Viet Nguyen, who is "empowering the community with open license climbing betas and source tools" (1). His goal for OpenBeta is to make climbing data more like an open source project, which in turn would help platforms like Mountain Project to increase their recommendation systems, geolocation data, and the accuracy of submissions (3). In addition to pushing for accessible data, the OpenBeta also posts articles that fit the needs of any climber in STEM: tutorials, current events, and project inspirations like recommendation systems and route quality maps. The community that OpenBeta is fostering aligns heavily with the forward mentality of climbing currently which is: don’t be a gatekeeper, spread the beta, and anyone is capable.  
      As a young climber and data scientist, I found myself incredibly inspired by OpenBeta’s work and wanted to support the nonprofit by using their data and some of their resources for my capstone project.  I want to leverage climbing data to influence decision making for climbers of all skill sets and as a result, contribute to the overarching goal of OpenBeta which is to make the sport of climbing safer, more knowledgeable, and more accessible. Recommendation systems are extremely powerful and if done well, can be a great tool for young climbers when exploring outdoor routes. To get a better understanding of the data and to ensure the viability of this goal, I first performed an exploratory data analysis of the OpenBeta data. 

```{r setup, include = FALSE, echo = FALSE, warning = FALSE}
library(tidyverse)
or_ratings <- read_csv("or-ratings.csv")
or_ratings
```

```{r, include = FALSE, echo = FALSE}
or_ratings <- or_ratings %>%
  mutate(trad = ifelse(str_extract(type, "tr") == "tr", 1, 0)) %>%
  mutate(sport = ifelse(str_extract(type, "sp") == "sp", 1, 0)) %>%
  mutate(trad = ifelse(is.na(trad), 0, trad)) %>%
  mutate(sport = ifelse(is.na(sport), 0, sport)) %>%
  filter(trad != sport) %>%
  mutate(type = ifelse(trad == 1, "trad", "sport")) %>%
  select(-trad, -sport)
```

```{r, include = FALSE, echo = FALSE}
or_quality <-
  read_csv("or_quality_data.csv")

or_quality
```

```{r, include = FALSE, echo = FALSE}
orGeo <- or_quality %>%
   mutate(lon = as.numeric(str_extract(parent_loc, '(-|)\\d+.\\d+')),
         lat = as.numeric(str_extract(parent_loc, '\\s(-|)\\d+.\\d+')))  %>%
  filter(!is.na(lat), !is.na(lon)) %>%
  mutate(route_ID = as.character(route_ID))
orGeo
```

```{r, include = FALSE, echo = FALSE}
#wcGeo <- rqGeo %>%
  #filter(state == "Oregon" | state == "Washington" | state == "California")

or_ratings <- or_ratings %>%
  mutate(route_id = as.character(route_id)) %>%
  inner_join(orGeo, by = c("route_id" = "route_ID"))

#wcGeo
or_ratings
```

```{r, include = FALSE, echo = FALSE}
my_levels = c(str_sort(or_ratings$grade) %>% unique())

or_ratings <- or_ratings %>%
  filter(grade %in% c(my_levels[1:2], my_levels[48:60], my_levels[3:47]))

or_ratings$grade <- as_factor(or_ratings$grade)

levels(or_ratings$grade) = c(my_levels[1:2], my_levels[48:60], my_levels[3:47]) # easy to expert

levels(or_ratings$grade)
```
## EDA 
       I knew I wanted to initially work with the West Coast for a couple reasons. For one, the Sierra Nevada of California and the Cascade Range of the Pacific Northwest are prime western U.S. rock climbing locales. In addition the West Coast is scattered with popular climbing spots (i.e. Yosemite, Joshua Tree, and Smith Rock) but there is a common misconception that these areas only have expert graded routes. In reality the opposite is true, and there are actually more beginner to moderate routes than expert ones.
       Furthermore, I decided to hone in on Oregon routes because it does not have widespread media coverage like California routes. Little people know that the birthplace of sport climbing was Oregon's Smith Rock State Park thanks to Alan Watts, a famous climbing pioneer, in 1986 (7). Not only is some of the best climbing in the nation found in Oregon's Smith Rock, but there are also hidden gems right in Portland's backyard that I had to do significant research as a climber to find. It would be even harder for a new climber to discover some of these on their own. not to mention that most of these routes are for climbers of all skill sets. The idea of my project is that anyone can have access to local classics even in lower grades. 

```{r, echo = FALSE}
library(ggthemes)
or_ratings <- or_ratings %>%
  mutate(level = case_when(
    grade %in% c(my_levels[1:2], my_levels[48:54]) ~ "easy",
    grade %in% c(my_levels[55:60], my_levels[3:12]) ~ "intermediate",
    grade %in% c(my_levels[13:32]) ~ "hard",
    grade %in% c(my_levels[33:47]) ~ "elite"))
or_ratings$level <- factor(or_ratings$level, 
                           levels = c("easy", "intermediate", "hard", "elite"))
or_ratings %>%
  group_by(grade, level) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(perc = count/sum(count)) %>%
  ggplot(aes(x = reorder(grade, -perc), y = perc)) +
  geom_col(aes(fill = level)) +
  scale_fill_brewer(palette = "Set2") +
  labs(x = "\nGrade (YDS)", y = "Percent\n", title = "Proportion of Routes in Oregon By Grade") + 
  theme_tufte() +
  theme(axis.text.x = element_text(angle = 45, size = 5, vjust = 0.5)) 
```
We are only using routes with grades that are in the Yosemite Decimal System, which is the traditional difficulty rating for routes in the US. According to the Yosemite Decimal System, a 5.0 to 5.7 is considered easy, 5.8 to 5.10 is considered intermediate, 5.11 to 5.12 is hard, and 5.13 to 5.15 is reserved for a very elite few. This means that the app will be of use to any climber, as some local classics come even in lower grades.

```{r, echo = FALSE}
or_ratings %>%
  group_by(grade, level) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(perc = count/sum(count)) %>%
  ungroup() %>%
  slice_max(order_by = perc, n = 5) %>%
  ggplot(aes(x = reorder(grade, -perc), y = perc)) +
  geom_col(aes(fill = level)) +
  scale_fill_brewer(palette = "Set2") +
  labs(x = "\nGrade (YDS)", y = "Percent\n", title = "Top Proportion of Routes per Grade in Oregon") + 
  theme_tufte() +
  theme(axis.text.x = element_text(angle = 45, size = 8, vjust = 0.5)) 
```


       One dataset I used from OpenBeta contains all route ratings in Oregon along with the route ID, grade, name, and type (such as trad, sport, ice, or bouldering). I focused only on trad and sport routes, which are two popular forms of rope-climbing. A limit of this method is that we lose routes that could be both sport and trad, but there are only a few routes in the data that satisfy this case. Another OpenBeta dataset I used had aggregate rating data along with the location of parent walls to use for plotting. The features I used from this dataset are the parent wall ID, name, location, state and the ARQI rating (this metric is explained later). 

      We can see that our data is dominated by sport routes (after all, Oregon *is* the birth place of sport climbing). This raises a concern for bias with an Item Based Collaborative Filtering recommendation system. With that being said, sport climbing is easily the most popular form of climbing nowadays. Not only is trad climbing out of date and mostly done by the pros, it is also extremely expensive and as a result, a barrier to entry to the sport. Therefore I felt okay about this data imbalance when making a recommendation to a new user: they probably don't want to be recommended trad routes for lower levels.
```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(RColorBrewer)
library(ggthemes)
or_ratings %>%
  ggplot(aes(x = state, fill = type)) +
  geom_histogram(stat = "count") +
  scale_fill_brewer(palette = "Set2") + 
  theme_tufte() + 
  labs(title = "Sport Route and Trad Route Counts in Oregon\n", 
       x = "\nState\n", y = "\nCount\n") + 
  theme(axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)) 
```
      As part of my exploratory data analysis, I also wanted to get a breakdown of classic routes. As a metric for route quality, we can look at the aggregate metric RQI or ARQI. The RQI is equal to S(1-1/N) where S is the average stars (or median) and N is the number of votes. As N approaches infinity, (1-1/N) approaches 1 and RQI approaches S. One issue with this metric is that harder routes get fewer ascents and therefore less votes, making it difficult for hard routes to make it into the "classic" class. We will use the Adjusted RQI (ARQI), which corrects for bias of RQI towards easier routes by adjusting the number of votes and therefore doesn't make route quality a "popularity metric." The ARQI is equal to S(1-1/Nw) where Nw is the number of weighted or adjusted votes and  is determined by the votes-per-route for each grade. 
       
According to OpenBeta, the categories for route quality are the following:

1. Classic: ARQI >= 3.5
2. Area Classic:  2.5 <= ARQI < 3.5 
3. Good: 1.5 <= ARQI < 2.5 
4. Bad: 0.5 >= ARQI < 1.5
5. Bomb: ARQI < 0.5 

```{r, include = FALSE, message = FALSE, echo = FALSE}
or_ratings <- or_ratings %>% 
  distinct() %>%
  mutate(class = case_when(
    ARQI_median >= 3.5 ~ "classic",
    ARQI_median >= 2.5 & ARQI_median < 3.5 ~ "area classic",
    ARQI_median >= 1.5 & ARQI_median < 2.5 ~ "good",
    ARQI_median >= 0.5 & ARQI_median < 1.5 ~ "bad",
    ARQI_median < 0.5 ~ "bomb")) %>%
  group_by(parent_sector) %>%
  mutate(best_route = route_name[which.max(ARQI_median)]) %>%
  ungroup()
    
or_ratings
```
## Class Distribution

Note that some routes with a lower ARQI may have a higher median rating. The ARQI takes the number of votes into consideration. This allows for a more accurate and fair route designation since we don't want just *any* route falling into a classic. 

```{r, echo = FALSE}
or_ratings$class <- factor(or_ratings$class, 
                                  levels = c("classic", "area classic", "good", "bad", "bomb"))
or_ratings %>% 
  filter(num_votes < 400) %>% #filter outliers
  select(num_votes, median_rating, class) %>%
  distinct() %>%
  ggplot(aes(num_votes, median_rating, group = class)) +
  geom_point(aes(color = class), alpha = 0.6, position = position_jitterdodge(jitter.width = .9, jitter.height = 0.1)) +
  scale_color_brewer(palette = "YlOrRd") +
  theme_tufte() +
  labs(x = "\nNumber of Votes\n", y = "\nMedian Rating\n", title = "Median Ratings vs Number of Votes by ARQI Class\n")
```
At the state level, we found that a majority of routes fall in the Good to Area Classic range with outliers in the Bad class. But what about at the grade level?
```{r, echo = FALSE}
or_ratings %>%
  group_by(state) %>%
  ggplot(aes(x = state, y = ARQI_median, fill = state)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set2") + 
  theme_tufte() +
  labs(x = "", y = "ARQI\n", title = "Distribution of ARQI Scores\n") +
  theme(legend.position = "none")
```

      We find that a majority of easy and intermediate routes are both classic and area classics, which supports my claim that anyone can climb a classic not only at their local crag but additionally famous big walls climbed by the legends. 

```{r, echo = FALSE}
or_ratings %>%
  group_by(level, class) %>%
  ggplot(aes(x = level)) +
  geom_bar(aes(fill = class), position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  theme_tufte() + 
  labs(x = "\nLevel\n", y = "Number of Routes\n", title = "Distribution of Route Classes by Grade Level")
  
```

## Route Mapping

      After some exploratory data analysis, I wanted to experiment with the functionality of my app. I wanted to design a route finder that would combine a recommendation and route ranking system in a map format using geolocation and ratings data. I used Plotly for interactivity, Mapbox for geocoding, and RShiny for construction of the web application. I accessed a public token from Mapbox in order to do some basic plotting and interactivity with Plotly. First I plotted all parent walls for both trad and sport and colored each wall based on route classes. Then with the idea that the user could filter routes by type, I plotted the routes by type and improved the formatting to be colored and sized by the ARQI (adjusted median rating). 

```{r, include = FALSE, echo = FALSE}
library(mapboxapi)

my_token <- 'pk.eyJ1Ijoibmhlcm5hbmRlejE5OTkiLCJhIjoiY2wzZGZjZDEwMDFyajNjbDVxMnJ2M2lwdSJ9.N9R9fzcgvK1ieQ_s5eVwQw'

#mb_access_token(my_token, install = TRUE, overwrite = TRUE)
#readRenviron("~/.Renviron")

Sys.setenv('MAPBOX_PUBLIC_TOKEN' = my_token)

Sys.getenv('MAPBOX_PUBLIC_TOKEN')

```

```{r, include = FALSE, warning = FALSE}
library(plotly)
```


```{r, message = FALSE, echo = FALSE, warning = FALSE}
fig <- or_ratings %>%
  plot_ly(lat = ~lat, 
          lon = ~lon, 
          mode = 'markers',
          type = 'scattermapbox',
          color = or_ratings$class,
          hoverinfo = 'text',
          text = paste("Parent wall: ", or_ratings$parent_sector,
                       "<br>",
                       "Example Route: ", or_ratings$route_name,
                       "<br>",
                       "Type: ", or_ratings$type_string, 
                       "<br>", 
                       "Class: ", or_ratings$class,
                       "<br>",
                       "ARQI: ", or_ratings$ARQI_median,
                       "<br>",
                       "Grade: ", or_ratings$grade)
                       ) %>%
  layout(
    mapbox = list(
      style = 'open-street-map', # or 'light'
      zoom = 4.5,
      center = list(lon = -121, lat = 44)
    )
  ) %>%
  config(mapboxAccessToken = Sys.getenv("MAPBOX_PUBLIC_TOKEN"))

fig
```

```{r, include = FALSE, echo = FALSE, warning = FALSE}
metric <- "ARQI_median"
sport <- 'sport'

df_sport <-orGeo %>%
  filter(type_string == sport) %>%
  group_by(sector_ID) %>%
  select(sector_ID, route_name, nopm_YDS, safety, metric)

name_sport <- orGeo %>%
  select(parent_sector, sector_ID, lon, lat) %>%
  filter(!duplicated(sector_ID))

agg_sport <- inner_join(df_sport, name_sport) 

orGeo_sport <- agg_sport %>%
  group_by(parent_sector) %>%
  mutate(n_routes = length(route_name)) %>%
  mutate(best_route_name = route_name[which.max(ARQI_median)])

orGeo_sport
```

## Plot 

I wanted the user to be able to set filters based on their skill set and the formatting of the plot to be simple, aesthetically pleasing and effective. I decided that the map would show routes in the user's applied filters that are colored and sized by route quality, and later on, would have a hover over that could provide more information about the wall and its routes. This make it easier for climbers to find all the information they need about the best possible routes in their ideal range. After finding an ideal format for this route finder, I could focus on the reccomender aspect of my shiny app.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
orGeo_sport %>%
  plot_ly(lat = ~lat, 
          lon = ~lon, 
          mode = 'markers',
          type = 'scattermapbox',
          text = orGeo_sport$parent_sector,
          hoverinfo = 'text',
          color = ~ orGeo_sport$ARQI_median,
          size = ~ orGeo_sport$ARQI_median) %>%
   layout(
    mapbox = list(
      style = 'open-street-map', # or 'light'
      zoom = 4.5,
      center = list(lon = -121, lat = 44)
    )
  ) %>%
  config(mapboxAccessToken = Sys.getenv("MAPBOX_PUBLIC_TOKEN"))

```

```{r, include=FALSE, echo = FALSE}
trad <- 'trad'

df_trad <- orGeo %>%
  filter(type_string == trad) %>%
  group_by(sector_ID) %>%
  select(sector_ID, route_name, nopm_YDS, safety, metric)

name_trad <- orGeo %>%
  select(parent_sector, sector_ID, lon, lat) %>%
  filter(!duplicated(sector_ID))

agg_trad <- inner_join(df_trad, name_trad) 

orGeo_trad <- agg_trad %>%
  group_by(parent_sector) %>%
  mutate(n_routes = length(route_name)) %>%
  mutate(best_route_name = route_name[which.max(ARQI_median)])

orGeo_trad

```


```{r, echo = FALSE, message = FALSE, warning = FALSE}
orGeo_trad %>%
  plot_ly(lat = ~lat, 
          lon = ~lon, 
          mode = 'markers',
          type = 'scattermapbox',
          text = orGeo_trad$parent_sector,
          hoverinfo = 'text', 
          color = ~ orGeo_trad$ARQI_median,
          size = ~ orGeo_trad$ARQI_median) %>%
  layout(
    mapbox = list(
      style = 'open-street-map', # or 'light'
      zoom = 4.5,
      center = list(lon = -120, lat = 44)
    )
  ) %>%
  config(mapboxAccessToken = Sys.getenv("MAPBOX_PUBLIC_TOKEN"))

```

# Recommendations

For the recommendation system, I created an item based collaborative-filtering recommender which asks the question “for users who climbed route x, which routes did they also climb?” and can predict routes based on past preferences of other users (1). Following the OpenBeta's structure, I wanted to make this aspect of my project a tutorial in order to provide transparency behind how recommendations are made and also a resource for future development. From what I've seen on famous route finders like theCrag or MP, these platforms do not implement recommendation systems for their routes (4, 5). They usually order the routes by popularity (average ratings or number of votes) but any data analyst using mean, median, or count as a metric for popularity should know to always consider outliers, skewed data, and relative proportions. In addition, I think having a simple recommendation system would be ideal for new climbers looking to find their first projects. I believe that a recommendation system combined with a map of route quality by the AQRI score also benefits the experienced climber too. For example, if they disagree with the location, rating or quality assessment of a certain route and as a result, a failed recommendation to the climber, the user can enter more data into the Mountain Project (where OpenBeta gets its data) which they believe is more accurate. When the data funneling into the model becomes more accurate, you get a better recommendation, a better user experience, increased retention, and so on.  

## Item Based Recommendation Tutorial

My main reference for creating a simple item based recommendation comes from (6). Here I am taking the complete cases of my entire ratings dataset. Since recommendation systems are so computationally heavy, I had to get rid of any observations with nulls to decrease the load. This is definitely a limitation to the accuracy of the recommendation. 

```{r, include = FALSE, echo = FALSE}
or_ratings <- or_ratings[complete.cases(or_ratings),]
```

We are going to choose a route that a climber from the Pacific Northwest may care about in order to get some recommendations based on that route. We could find the most popular route by looking at the route with the most votes, but we can now apply our new knowledge of the ARQI metric to get the route with the best quality.

```{r}
or_ratings %>%
  group_by(route_id) %>%
  select(route_id, ARQI_median) %>%
  distinct() %>%
  arrange(desc(ARQI_median)) %>%
  head(3)
```

```{r}
or_ratings %>% 
  filter(route_id == "105892195")  %>%
  select(route_id, route_name, grade, type, parent_sector, class, level) %>%
  slice(1)
```
## Overview 

The route ID with the greatest ARQI is a route called "Spank the Monkey" which is a classic, easy 5.1 sport route from the Monkey Face wall which is a very popular wall in Smith Rock. Item Based Collaborative Filtering answers the question "climbers who climbed Spank the Monkey also climbed...?"
      
![Monkey Rock at Smith Rock State Park in Oregon.](~/Downloads/MSDS_capstone/content/post/2016-12-30-hello-markdown/dm5314-climbers-on-monkey-face-rock-or-ed-cooper-photography.jpeg) 
*Monkey Rock at Smith Rock State Park in Oregon*


## Create User-Product Matrix 

First we spread out our users, route ID, and ratings across a pivot table that we convert to a simple matrix, called the user-product matrix, for calculating similarity scores. 

```{r, warning = FALSE}
or_wide <- or_ratings %>%
  select(users, route_id, ratings) %>%
  distinct() %>%
  pivot_wider(names_from = route_id, values_from = ratings)

row.names(or_wide) <- or_wide$users
or_wide$users <- NULL
or_mat <- (as.matrix(or_wide))
or_mat[1:3, 1:3]
```

## Calculate Degree of Sparsity 

The issue with the user-product matrix is its degree of sparsity. With this matrix, 99% of cells lack data which is an obvious limitation to this method. However, we may be able to tackle this issue with cosine similarity. 

```{r}
sum(is.na(or_mat))/(ncol(or_mat) * nrow(or_mat))
```

## Use Cosine Similarity to Measure Distance 

We can use the cosine similarity to measure distances versus the Euclidean distance since the cosine distance looks at directional similarity rather than magnitudal differences. Here I am hoping to capture beyond the numbers and get more content out of them. For example, a route that gets a rating of 3.0 four times and 4.0 eight times will have a 100% similarity score to a route that has one 3.0 ratings and two 4.0 ratings. If we were computing euclidean distance, this would give us a similarity of only 13%. I'm hoping that this method can be viable in tackling the data sparsity issue. 

```{r, warning = FALSE, message = FALSE}
library(lsa)

route_x <- c(4, 8)
route_y <- c(1, 2)

cosine(route_x, route_y) # cosine
1/(1 + sqrt((1-4)^2 + (2-8)^2)) # euclidean
```

## Compute 

We can build a function to compute the similarity for various routes in our matrix. 

```{r}
cos_similarity = function(A,B){
  num = sum(A *B, na.rm = T)
  den = sqrt(sum(A^2, na.rm = T))*sqrt(sum(B^2, na.rm = T)) 
  result = num/den

  return(result)
}
```

##  Product-Product matrix 

Now we can apply this function to obtain the product-product matrix. To prevent memory overload, we create a function to calculate the similarity only on the route we choose. 

```{r}
route_recommendation = function(route_id, rating_matrix = or_mat, n_recommendations = 5){

  route_index = which(colnames(rating_matrix) == route_id)

  similarity = apply(rating_matrix, 2, FUN = function(y) 
                      cos_similarity(rating_matrix[,route_index], y))

  recommendations = tibble(ID = names(similarity), 
                               similarity = similarity) %>%
    filter(ID!= route_id) %>% 
    top_n(n_recommendations, similarity) %>%
    arrange(desc(similarity)) 

  return(recommendations)

}
```

## Get Recommendations

Our function returns the top 5 similar routes to "Spank the Monkey."

```{r}
my_route <- "105892195"
recommendations = route_recommendation(my_route)
recommendations
```

## Join with Ratings Data 

Next, we can join back to our original data to get information about the recommended routes. We now have information about similar routes climbed by users that also climbed and rated Spank the Monkey in a similar way. The most similar route to Spank the Monkey is The Conspiracy which is located at the Red Wall (also in Smith Rock). In the Shiny App, I wanted the user to be able to explore the parent walls of the recommended routes so that they could also see the proximity of like-routes. To build upon this method, one could also implement machine learning frameworks such as K-Nearest Neighbors to compute the cosine similarity more accurately with cross validation and hyperparameter tuning. My primary focus on the first rollout of my Shiny app was the user experience, not the model building, but this is an ongoing project that I plan to keep building upon and improving. 

```{r, echo = FALSE}
or_sub <- or_ratings %>%
  mutate(route_id = as.character(route_id))

rec_tbl <- recommendations %>%
  mutate(ID = as.character(ID)) %>%
  left_join(or_sub, by = c("ID" = "route_id")) %>%
  select(ID, name, similarity, grade, type, state, sector_ID, parent_sector, lon, lat, grade, ARQI_median, class, level) %>%
  distinct() 

rec_tbl
```

## Shiny App 
     With the proof of concept complete I was able to bring all the working pieces together in constructing my Shiny app. As seen below, the user can apply basic filters such as the grade range and type to get a quick map of available routes. When the user hovers over a point on the map, they get an overview of the parent wall which includes the name and location of the wall and information about an example route at the wall. If they click the parent wall, they can get a list of all the routes at the wall with more granularity. The table below includes additional metadata such as the number of votes, the grade class, the level class and more for each route. It is also ordered from highest rating to lowest which makes it easy for users to find the top routes at each parent sector.

```{r}
knitr::include_url("https://nhernandez.shinyapps.io/climbing_app/", height = "1000px")
```
**Link:** https://nhernandez.shinyapps.io/climbing_app/

     The incorporation of the route recommender is my favorite part of the Shiny app. If the user clicks on a row of the main table, a second table popups to the right of the plot with the top five recommendations for that route. This mini table also has metadata about the various routes and specifically the parent wall that each route is located at. With this information the user can enter individual parent walls (see the “Enter a Parent Wall" input option on the top left panel) for plotting, which allows the users to see where recommended routes are located relative to the initial parent wall they clicked on the map.  
     I wanted to make the functionality of the app as user friendly as possible. I wanted to match the natural intuition of user experience by making the app be fluid and continuous, but I also wanted to provide guidance if a user gets stuck. There are help buttons that provide an overview of class and grade distributions that were explained earlier in this article. This gives the user a solid place to start for navigating routes if they're unsure what they want. Notice, however, that the help buttons have to be clicked in order to trigger the pop-ups. I don't want to "scare" the user away with information overload by covering the entire shiny app with text. I also don't want users to feel like there is a *right* place to start -- I want the experience to be their own and freely structured.   
     Putting my technical skills into a topic that I'm passionate about really allowed me to construct an app that was effective and multidimensional. I was inspired by the OpenBeta’s work to produce a project that aligns with making the sport of rock climbing more accessible and supporting open source projects in software development. I felt that my unique experiences as a data scientist and climber have allowed me to give back to both communities with this project. While my project is only a resource for the Oregon climbing community, I believe that it could be scaled out nationally and equally useful. I’m excited to see where the potential of this sport goes in the next couple of years and I hope to reflect such change in my project.   

# Conclusion 

     One limitation of my project is the restriction placed on the data I’m using. Following a legal battle with onX regarding a copyright infringement, which OpenBeta won (as noncommercial and educational factual data cannot be copyrighted), OpenBeta is working to release their data under a public domain, permissive license (1,3). For this reason, all of OpenBeta’s current datasets only include user ratings up to 2020, and it doesn’t seem like they will be able to update them by August. Therefore, there is a missed opportunity for generating better recommendations without input following the increase of climbers after Tokyo. In the future, climbing data from the Mountain Project will be streamed directly into the model prior to rollouts and will allow for optimal and more accurate results or recommendations.  
      My route finder is free resource to the Oregon climbing community which streamlines the route searching process for climbers of varying skill sets. I also hope that this blog post serves as a resource that any stakeholder (like participants, spectators, media, sponsors, businesses, brands, developers, analysts etc.) could benefit from. Guiding the recent explosion of climbers properly could help make the sport extremely profitable and the climbing community greater and diverse. I hope to help dissolve barriers to entry by providing a tool to climbers that keeps them safe, in the loop, and connected to other climbers. For the data community, I also want to promote the open source movement in software and data as I strongly believe that it is essential in encouraging innovation, attracting diverse talent, and broadening perspectives within tech. 

1. https://OpenBeta.io/
2. https://www.forbes.com/sites/michellebruton/2021/11/24/interest-in-climbing-and-gym-memberships-have-spiked-following-sports-tokyo-olympics-debut/?sh=3daaf24326a8
3. https://www.climbing.com/news/mountain-project-OpenBeta-and-the-fight-over-climbing-data-access/
4. https://www.thecrag.com/
5. https://www.mountainproject.com/
6. https://anderfernandez.com/en/blog/how-to-code-a-recommendation-system-in-r/
7. https://www.climbing.com/videos/pioneering-smith-rock-alan-watts-and-the-birth-of-us-sport-climbing/

